{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0pUk5o+QW8WoYFmuPSq8D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**1. Grey Wolf Optimization using relu Activation function**"],"metadata":{"id":"NClUMysfW8n7"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"gFLmebr-VeXH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2. Grey Wolf Optimization using sigmoid Activation function**"],"metadata":{"id":"WB6tueotW4sh"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='sigmoid', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='sigmoid'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n"],"metadata":{"id":"3Jg-PcHcCYqI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Grey Wolf Optimization using Squared Sine Activation  function**"],"metadata":{"id":"m7HwbywZW0oe"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Custom Squared Sine Activation Function\n","class SquaredSineActivation(tf.keras.layers.Layer):\n","    def __init__(self, omega=1.0, **kwargs):\n","        super(SquaredSineActivation, self).__init__(**kwargs)\n","        self.omega = omega\n","\n","    def call(self, inputs):\n","        return tf.sin(self.omega * inputs) ** 2\n","\n","# CNN architecture with Squared Sine Activation\n","def create_cnn_model(activation_function):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation=activation_function, input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation=activation_function))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"XbwFWPocZc5b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4. Grey Wolf Optimization using tanh Activation function**\n"],"metadata":{"id":"9o1JKcrEWtiI"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='tanh', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='tanh'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"vsyOYWdVVwoQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5. Grey Wolf Optimization using SoftSign  Activation function**\n"],"metadata":{"id":"2tgb8qnxWpgy"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='softsign', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='softsign'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"AVSKtekbejOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6. Grey Wolf Optimization using SoftPlus Activation function**"],"metadata":{"id":"DJ7472x2XjcT"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='softplus', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='softplus'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"ztGbSfjPXaAh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**7.Grey Wolf Optimization using swish Activation function**"],"metadata":{"id":"pCmlBOxDX9CR"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='swish', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='swish'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"y6Vxu5gAXqJR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**8. Grey Wolf Optimization using mish Activation function**"],"metadata":{"id":"DkoqCnh6Y-8G"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='mish', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='mish'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"JogyKTrSXrKE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**9. Grey Wolf Optimization using HardSigmoid Activation function**"],"metadata":{"id":"IOfWVBOqi4R5"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Define the Hard Sigmoid Activation Layer\n","class HardSigmoidActivation(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super(HardSigmoidActivation, self).__init__(**kwargs)\n","\n","    def call(self, inputs):\n","        return tf.keras.backend.hard_sigmoid(inputs)\n","\n","def create_cnn_model(activation_function):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation=activation_function, input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation=activation_function))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"6bjCXA6uXsFb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10. Grey Wolf Optimization using selu Activation function**"],"metadata":{"id":"x0b6IOeqjwhp"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='selu', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='selu'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"rnepyCn9Xuqd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**11. Grey Wolf Optimization using elu Activation function**"],"metadata":{"id":"snlA6UbjkQm4"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='elus', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='elu'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"dHZd8Ch2XvbS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**12. Grey Wolf Optimization using PRelu Activation function**"],"metadata":{"id":"GH2uQz0rlIFl"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='PReLU', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='PReLU'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"qhb8eSJZXwNV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**13. Grey Wolf Optimization using LeakyRelu Activation function**"],"metadata":{"id":"76Vgtcc_k8m7"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# CNN architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='LeakyReLU', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='LeakyReLU'))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"2wP4pcIDXw_k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**14. Grey Wolf Optimization using GELU Activation function**"],"metadata":{"id":"WpKlOs1MvWl2"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Define GELU activation function\n","def gelu(x):\n","    cdf = 0.5 * (1.0 + tf.tanh((tf.sqrt(2 / tf.constant(np.pi)) * (x + 0.044715 * x ** 3))))\n","    return x * cdf\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# CNN architecture with GELU Activation\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation=gelu, input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation=gelu))\n","model.add(Dense(10, activation='softmax'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# Defining the objective function for Grey Wolf Optimizer\n","def objective_function(params):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params[0]),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(params[1]), epochs=int(params[2]), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","# Defining the search space for GWO\n","param_boundaries = [\n","    (1e-6, 1e-2), # Learning rate\n","    (32, 128),     # Batch size\n","    (5, 50)        # Epochs\n","]\n","# Number of wolves in the swarm\n","num_wolves = 50\n","# Number of iterations\n","num_iterations = 100\n","# Grey Wolf Optimizer\n","class GreyWolfOptimizer:\n","    def __init__(self, num_wolves, objective_function, param_boundaries):\n","        self.num_wolves = num_wolves\n","        self.objective_function = objective_function\n","        self.param_boundaries = param_boundaries\n","\n","    def optimize(self, num_iterations):\n","        # Initialization\n","        wolves = [self._initialize_wolf() for _ in range(self.num_wolves)]\n","\n","        for iteration in range(num_iterations):\n","            for i in range(self.num_wolves):\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[0] - wolves[i][0]  # Equation (3.6)\n","                C = 2 * c[0]  # Equation (3.8)\n","                D = abs(C * wolves[i][0] - A)  # Equation (3.10)\n","                X1 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[1] - wolves[i][1]  # Equation (3.6)\n","                C = 2 * c[1]  # Equation (3.8)\n","                D = abs(C * wolves[i][1] - A)  # Equation (3.10)\n","                X2 = A - self._get_random() * D  # Equation (3.7)\n","\n","                a, b, c = self._select_three_random_wolves(i)\n","                A = 2 * a[2] - wolves[i][2]  # Equation (3.6)\n","                C = 2 * c[2]  # Equation (3.8)\n","                D = abs(C * wolves[i][2] - A)  # Equation (3.10)\n","                X3 = A - self._get_random() * D  # Equation (3.7)\n","\n","                # Ensuring the search space boundaries\n","                X1 = self._clip(X1, *self.param_boundaries[0])\n","                X2 = self._clip(X2, *self.param_boundaries[1])\n","                X3 = self._clip(X3, *self.param_boundaries[2])\n","\n","                # Updating the position of the current wolf\n","                new_position = [X1, X2, X3]\n","                new_fitness = self.objective_function(new_position)\n","\n","                # Comparing the fitness of the new position with the current position\n","                if new_fitness < wolves[i][-1]:\n","                    wolves[i] = new_position + new_fitness\n","\n","            # Sorting the wolves based on fitness\n","            wolves.sort(key=lambda x: x[-1])\n","\n","        # Returning the best solution found\n","        return wolves[0][:-1]\n","\n","    def _initialize_wolf(self):\n","        position = [self._get_random_in_range(*boundaries) for boundaries in self.param_boundaries]\n","        fitness = self.objective_function(position)\n","        return position + fitness\n","\n","    def _select_three_random_wolves(self, current_index):\n","        indices = [i for i in range(self.num_wolves) if i != current_index]\n","        selected_indices = self._get_random_sample(indices, size=3)\n","        selected_wolves = [wolves[i] for i in selected_indices]\n","        return selected_wolves\n","\n","    @staticmethod\n","    def _get_random():\n","        return tf.random.uniform(shape=(), minval=0, maxval=1)\n","\n","    @staticmethod\n","    def _get_random_in_range(min_val, max_val):\n","        return tf.random.uniform(shape=(), minval=min_val, maxval=max_val)\n","\n","    @staticmethod\n","    def _get_random_sample(population, size):\n","        return tf.random.shuffle(population)[:size]\n","\n","    @staticmethod\n","    def _clip(value, min_val, max_val):\n","        return tf.clip_by_value(value, min_val, max_val)\n","# Creating a Grey Wolf Optimizer object\n","gwo = GreyWolfOptimizer(num_wolves, objective_function, param_boundaries)\n","# Finding the optimal parameters\n","optimal_params = gwo.optimize(num_iterations)\n","# Displaying the best parameters found\n","print(f\"Best parameters found by GWO: {optimal_params}\")\n","# Compiling the model with the best parameters\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_params[0]),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Training the model with the best parameters\n","history = model.fit(X_train, y_train, batch_size=int(optimal_params[1]), epochs=int(optimal_params[2]), verbose=1)\n","# Evaluating the model on the test set\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"TeIv1ZQhvjFT"},"execution_count":null,"outputs":[]}]}