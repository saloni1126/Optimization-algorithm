{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2hp4zJE1YdUBvkkXE6V8c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**1.Genetic Algorithm using relu Activation function**"],"metadata":{"id":"3DqqXL6L1EWw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4I2KEodk0rOt"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n"]},{"cell_type":"markdown","source":["**2.Genetic Algorithm using sigmoid Activation function**"],"metadata":{"id":"Kjy3HpOc1aYs"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='sigmoid', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='sigmoid'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"W5Ho6Nu3047B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Genetic Algorithm using Squared Sine Activation function**"],"metadata":{"id":"FQwFVQY-1iQn"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Custom Squared Sine Activation Function\n","class SquaredSineActivation(tf.keras.layers.Layer):\n","    def __init__(self, omega=1.0, **kwargs):\n","        super(SquaredSineActivation, self).__init__(**kwargs)\n","        self.omega = omega\n","\n","    def call(self, inputs):\n","        return tf.sin(self.omega * inputs) ** 2\n","\n","# CNN architecture with Squared Sine Activation\n","def create_cnn_model(activation_function):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation=activation_function, input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation=activation_function))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"kDsXQ6tq1p84"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4. Genetic Algorithm using tanh Activation function**"],"metadata":{"id":"o5lPTA-_1qag"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='tanh', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='tanh'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"SN21MjiM1yUk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5. Genetic Algorithm using Softsign Activation function**"],"metadata":{"id":"2s3e3SzH1yvM"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='softsign', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='softsign'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"4_k-KUFZ2B_1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6. Genetic Algorithm using Softplus Activation function**"],"metadata":{"id":"iRD083RE2CPu"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='softplus', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='softplus'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"NVv5Z9072CqG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**7. Genetic Algorithm using Swish Activation function**"],"metadata":{"id":"CM_OGxf32C6l"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='swish', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='swish'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"k4HmBajQ2Od0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**8. Genetic Algorithm using mish Activation function**"],"metadata":{"id":"JsidHsDw2Ove"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='mish', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='mish'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"MGyOS3W-2Vmd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**9. Genetic Algorithm using HardSigmoid Activation function**"],"metadata":{"id":"eElKYuPE2V2r"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","# Define the Hard Sigmoid Activation Layer\n","class HardSigmoidActivation(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super(HardSigmoidActivation, self).__init__(**kwargs)\n","\n","    def call(self, inputs):\n","        return tf.keras.backend.hard_sigmoid(inputs)\n","\n","def create_cnn_model(activation_function):\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation=activation_function, input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation=activation_function))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"cqjbW_o_2cs8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**10. Genetic Algorithm using Selu Activation function**"],"metadata":{"id":"F3_5fLsk2c-m"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='selu', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='selu'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"JJ5nKNsJ2dZF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**11. Genetic Algorithm using elu Activation function**"],"metadata":{"id":"S9U8FfIg2d1s"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='elu', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='elu'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"Ju7QOUwQ2qfu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**12. Genetic Algorithm using PRelu Activation function**"],"metadata":{"id":"wWTqrYRM2rD8"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='PRelu', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='PRelu'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"eGrhL32S2rz8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**13. Genetic Algorithm using LeakyRelu Activation function**"],"metadata":{"id":"2lifMghP2sN7"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Define the CNN architecture\n","def create_cnn_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation=' LeakyRelu', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation=' LeakyRelu'))\n","    model.add(Dense(10, activation='softmax'))\n","    return model\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"urCM2C9k2sqV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**14.Genetic Algorithm using GELU Activation function**"],"metadata":{"id":"ISg02bSKwD1a"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# Define GELU activation function\n","def gelu(x):\n","    cdf = 0.5 * (1.0 + tf.tanh((tf.sqrt(2 / tf.constant(np.pi)) * (x + 0.044715 * x ** 3))))\n","    return x * cdf\n","\n","# Loading MNIST data set\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalizing the pixel values to the range [0, 1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","\n","# Converting labels to categorical\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# CNN architecture with GELU Activation\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation=gelu, input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation=gelu))\n","model.add(Dense(10, activation='softmax'))\n","\n","# Function to evaluate the model with given parameters\n","def evaluate_model(learning_rate, batch_size, epochs):\n","    model = create_cnn_model()\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n","                        batch_size=int(batch_size), epochs=int(epochs), verbose=0)\n","\n","    train_loss = history.history['loss'][-1]\n","    train_accuracy = history.history['accuracy'][-1]\n","\n","    return [train_loss, 1 - train_accuracy]\n","\n","# Genetic Algorithm\n","def genetic_algorithm(population_size, generations):\n","    # Initialize population with random parameters\n","    population = np.random.rand(population_size, 3)\n","    best_solution = None\n","    best_fitness = float('inf')\n","\n","    for generation in range(generations):\n","        # Evaluate fitness for each individual in the population\n","        fitness_values = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Select the top individuals based on fitness\n","        sorted_indices = np.argsort(fitness_values)\n","        top_indices = sorted_indices[:int(population_size / 2)]\n","        top_population = population[top_indices]\n","\n","        # Crossover (single-point crossover)\n","        crossover_points = np.random.randint(1, 3, int(population_size / 2))\n","        crossover_population = np.zeros_like(top_population)\n","\n","        for i in range(0, len(crossover_points), 2):\n","            point = crossover_points[i]\n","            crossover_population[i, :] = np.concatenate([top_population[i, :point], top_population[i + 1, point:]])\n","            crossover_population[i + 1, :] = np.concatenate([top_population[i + 1, :point], top_population[i, point:]])\n","\n","        # Mutation\n","        mutation_rate = 0.1\n","        mutation_mask = np.random.rand(int(population_size / 2), 3) < mutation_rate\n","        mutation_population = np.random.rand(int(population_size / 2), 3) * mutation_mask\n","\n","        # Create the next generation\n","        population = np.concatenate([top_population, crossover_population, mutation_population])\n","        population_fitness = np.apply_along_axis(evaluate_model, 1, population)\n","\n","        # Update the best solution\n","        best_index = np.argmin(population_fitness)\n","        if population_fitness[best_index] < best_fitness:\n","            best_solution = population[best_index]\n","            best_fitness = population_fitness[best_index]\n","\n","    return best_solution\n","\n","# Set the parameters for the genetic algorithm\n","population_size = 50\n","generations = 100\n","\n","#Run the genetic algorithm\n","best_params = genetic_algorithm(population_size, generations)\n","\n","# Display the best parameters found\n","print(f\"Best parameters found by Genetic Algorithm: {best_params}\")\n","\n","# Compile the model with the best parameters\n","best_model = create_cnn_model()\n","best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[0]),\n","                   loss='categorical_crossentropy',\n","                   metrics=['accuracy'])\n","\n","# Train the model with the best parameters\n","history = best_model.fit(X_train, y_train, batch_size=int(best_params[1]), epochs=int(best_params[2]), verbose=1)\n","\n","# Evaluate the model on the test set\n","test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"],"metadata":{"id":"H3aKmjuPwIx_"},"execution_count":null,"outputs":[]}]}